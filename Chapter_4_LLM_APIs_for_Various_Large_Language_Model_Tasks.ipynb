{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import json\n",
        "import requests\n",
        "from abc import ABC, abstractmethod\n",
        "os.environ[\"API_TOKEN\"]= \"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\"\n",
        "\n",
        "'''\n",
        "Image file Credits: wikipedia , Mukhiddinov, Mukhriddin & Muminov, Azamjon & Cho, Jinsoo. (2022). Improved Classification Approach for Fruits and Vegetables Freshness Based on Deep Learning. Sensors. 22. 8192. 10.3390/s22218192.\n",
        "\n",
        "audio file credits : kaggle\n",
        "\n",
        "'''"
      ],
      "metadata": {
        "id": "AK56_YYMpeqX"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#LLM Tasks for Demo\n",
        "\n",
        "\n",
        "\n",
        "1. Fill Mask\n",
        "2. Summarization\n",
        "3. Question Answering\n",
        "4. Table Question Answering\n",
        "5. Semantic Similarity\n",
        "6. Token Classification\n",
        "7. Zero-Shot Classification\n",
        "8. Automatic Speech Recognition\n",
        "9. Image Classification\n",
        "10. Object Detection\n",
        "\n"
      ],
      "metadata": {
        "id": "-QVLAGAhXFL7"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Boilerplate code"
      ],
      "metadata": {
        "id": "r36v3Ykfx_XF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "import requests\n",
        "from IPython.display import display\n",
        "from ipywidgets import interact, widgets\n",
        "import os\n",
        "\n",
        "API_TOKEN = os.environ[\"API_TOKEN\"]\n",
        "\n",
        "def select_llm_task(task):\n",
        "    \"\"\"\n",
        "    Selects a specific LLM task and returns the response from the API.\n",
        "\n",
        "    Args:\n",
        "        task (str): The name of the LLM task to be performed.\n",
        "\n",
        "    Returns:\n",
        "        dict: The response from the API.\n",
        "\n",
        "    Raises:\n",
        "        ValueError: If an invalid LLM task is selected.\n",
        "    \"\"\"\n",
        "\n",
        "    # Set the authorization header using the API token\n",
        "    headers = {\"Authorization\": f\"Bearer {API_TOKEN}\"}\n",
        "\n",
        "    #Remove white spaces\n",
        "    tasks = task.strip()\n",
        "\n",
        "     # Define a dictionary mapping each task to its corresponding API URL and payload\n",
        "    tasks = {\n",
        "        \"Fill Mask\": {\n",
        "            \"API_URL\": \"https://api-inference.huggingface.co/models/bert-base-uncased\",\n",
        "            \"payload\": \"The earth is a big [MASK]\"\n",
        "        },\n",
        "        \"Summarization\": {\n",
        "            \"API_URL\": \"https://api-inference.huggingface.co/models/facebook/bart-large-cnn\",\n",
        "            \"payload\": \"The quick brown fox jumps over the lazy dog. The dog was not amused.\"\n",
        "        },\n",
        "        \"Question Answering\": {\n",
        "            \"API_URL\": \"https://api-inference.huggingface.co/models/deepset/roberta-base-squad2\",\n",
        "            \"payload\": {\"context\": \"The earth is the third planet from the sun.\", \"question\": \"Which planet is the third from the sun?\"}\n",
        "        },\n",
        "        \"Table Question Answering\": {\n",
        "            \"API_URL\": \"https://api-inference.huggingface.co/models/google/tapas-base-finetuned-wtq\",\n",
        "            \"payload\": {\n",
        "                \"inputs\": {\n",
        "                    \"query\": \"What is the total population of the cities?\",\n",
        "                    \"table\": {\n",
        "                        \"City\": [\"New York\", \"Los Angeles\", \"Chicago\"],\n",
        "                        \"Population\": [\"8,398,748\", \"3,990,456\", \"2,705,994\"]\n",
        "                    },\n",
        "                }\n",
        "            }\n",
        "        },\n",
        "        \"Semantic Similarity\": {\n",
        "            \"API_URL\": \"https://api-inference.huggingface.co/models/sentence-transformers/all-MiniLM-L6-v2\",\n",
        "            \"payload\": {\n",
        "                \"inputs\": {\n",
        "                    \"source_sentence\": \"The sky is blue\",\n",
        "                    \"sentences\": [\"The sky is clear today\", \"It is raining\", \"Look at the bright blue sky\"]\n",
        "                }\n",
        "            }\n",
        "        },\n",
        "        \"Token Classification\": {\n",
        "            \"API_URL\": \"https://api-inference.huggingface.co/models/dbmdz/bert-large-cased-finetuned-conll03-english\",\n",
        "            \"payload\": {\"inputs\": \"My name is John Doe and I live in New York City\"}\n",
        "        },\n",
        "        \"Zero-Shot Classification\": {\n",
        "            \"API_URL\": \"https://api-inference.huggingface.co/models/facebook/bart-large-mnli\",\n",
        "            \"payload\": {\n",
        "                \"inputs\": \"The stock market is likely to rise tomorrow\",\n",
        "                \"parameters\": {\"candidate_labels\": [\"finance\", \"sports\", \"health\"]}\n",
        "            }\n",
        "        },\n",
        "        \"Automatic Speech Recognition\": {\n",
        "            \"API_URL\": \"https://api-inference.huggingface.co/models/facebook/wav2vec2-base-960h\",\n",
        "            \"payload\": \"/content/harvard.wav\"\n",
        "        },\n",
        "        \"Audio Classification\": {\n",
        "            \"API_URL\": \"https://api-inference.huggingface.co/models/superb/hubert-large-superb-er\",\n",
        "            \"payload\": \"/content/sample1.flac\"\n",
        "        },\n",
        "        \"Image Classification\": {\n",
        "            \"API_URL\": \"https://api-inference.huggingface.co/models/google/vit-base-patch16-224\",\n",
        "            \"payload\": \"/content/trees.jpg\"\n",
        "        },\n",
        "        \"Object Detection\": {\n",
        "            \"API_URL\": \"https://api-inference.huggingface.co/models/facebook/detr-resnet-50\",\n",
        "            \"payload\": \"/content/multiple_objects.jpg\"\n",
        "        }\n",
        "    }\n",
        "    # Check if the selected task is valid\n",
        "    if task not in tasks:\n",
        "        raise ValueError(\"Invalid LLM task selected.\")\n",
        "    # Retrieve the API URL and payload for the selected task\n",
        "    task_info = tasks[task]\n",
        "    API_URL = task_info[\"API_URL\"]\n",
        "    payload = task_info[\"payload\"]\n",
        "\n",
        "    def request(payload):\n",
        "        \"\"\"\n",
        "        Sends a request to the API with the specified payload and returns the response.\n",
        "\n",
        "        Args:\n",
        "            payload: The payload to be sent in the request.\n",
        "\n",
        "        Returns:\n",
        "            dict: The response from the API.\n",
        "        \"\"\"\n",
        "\n",
        "        # If the payload is a string and the task involves file handling (e.g., audio or image tasks), read the file as binary\n",
        "        if isinstance(payload, str) and task in [\"Automatic Speech Recognition\", \"Audio Classification\", \"Image Classification\", \"Object Detection\"]:\n",
        "            with open(payload, \"rb\") as f:\n",
        "                data = f.read()\n",
        "            response = requests.request(\"POST\", API_URL, headers=headers, data=data)\n",
        "        else:\n",
        "            # Otherwise, convert the payload to JSON and send the request\n",
        "            data = json.dumps(payload)\n",
        "            # Return the response and the payload\n",
        "            response = requests.request(\"POST\", API_URL, headers=headers, data=data)\n",
        "        return {\"response\": json.loads(response.content.decode(\"utf-8\")), \"payload\": payload}\n",
        "    # Call the request function with the payload for the selected task\n",
        "    return request(payload)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "n1EMQOY3mIRT"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Example usage of the function\n",
        "response = select_llm_task(task=\"Token Classification\")\n",
        "\n",
        "# Display the response\n",
        "display(response)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 208
        },
        "id": "Hk3ysDvWRDy_",
        "outputId": "f87bb4d8-754a-4767-aec2-666920e25c14"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "{'response': [{'entity_group': 'PER',\n",
              "   'score': 0.9970178604125977,\n",
              "   'word': 'John Doe',\n",
              "   'start': 11,\n",
              "   'end': 19},\n",
              "  {'entity_group': 'LOC',\n",
              "   'score': 0.9992094039916992,\n",
              "   'word': 'New York City',\n",
              "   'start': 34,\n",
              "   'end': 47}],\n",
              " 'payload': {'inputs': 'My name is John Doe and I live in New York City'}}"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Pa7pOuFQZus4"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}